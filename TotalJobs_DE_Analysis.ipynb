{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bc3ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TotalJobs UK Data Engineer Job Analysis\n",
    "\n",
    "# üì• Step 1: Load and Inspect Data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/de_totaljobs_test2.csv\")\n",
    "\n",
    "# Inspect structure\n",
    "print(df.info())\n",
    "print(df.head(2))\n",
    "\n",
    "# üóÇÔ∏è Check missing values\n",
    "df.isna().sum()\n",
    "\n",
    "# üßº Clean: Drop NaNs in location-related column\n",
    "df.dropna(subset=['unitary_authority'], inplace=True)\n",
    "\n",
    "# üï∞Ô∏è Convert publish date to datetime\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "df['week'] = df['published_at'].dt.strftime('%Y-%U')\n",
    "\n",
    "# üìä Weekly Job Postings Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['week'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title(\"Weekly Distribution of Job Postings\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Jobs\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìç Map: Jobs by Region\n",
    "region_counts = df['unitary_authority'].value_counts().reset_index()\n",
    "region_counts.columns = ['region', 'job_count']\n",
    "print(region_counts.head())\n",
    "\n",
    "# üåç Load UK administrative boundaries (GeoJSON or SHP file required)\n",
    "uk_map = gpd.read_file(\"../data/uk_unitary_authorities.geojson\")\n",
    "uk_map = uk_map.merge(region_counts, left_on=\"CTYUA24NM\", right_on=\"region\", how=\"left\")\n",
    "uk_map['job_count'] = uk_map['job_count'].fillna(0)\n",
    "\n",
    "# Plot map\n",
    "uk_map.plot(column='job_count', cmap='Blues', edgecolor='black', legend=True, figsize=(10, 12))\n",
    "plt.title(\"Job Distribution by Region\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# üîç Extract Skills from Job Content\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "skills_list = ['Python', 'SQL', 'Azure', 'AWS', 'GCP', 'Spark', 'Databricks']\n",
    "def extract_skills(text):\n",
    "    return [skill for skill in skills_list if re.search(fr'\\b{re.escape(skill)}\\b', str(text), re.IGNORECASE)]\n",
    "\n",
    "all_skills = df['job_content'].apply(extract_skills)\n",
    "flat_skills = [skill for sublist in all_skills for skill in sublist]\n",
    "skills_freq = Counter(flat_skills)\n",
    "\n",
    "# Plot Top Skills\n",
    "pd.Series(skills_freq).sort_values(ascending=True).plot(kind='barh', figsize=(8, 6), color='teal')\n",
    "plt.title(\"Top Technical Skills in Data Engineer Job Descriptions\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìå Save clean data\n",
    "df.to_csv(\"../data/de_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
